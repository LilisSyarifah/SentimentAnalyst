{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"sa.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># SpeakYourMind : YEP hosts free mental health...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ed Sheeran and Ella Eyre lead the way as stars...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day of play to say You Matter : youths host fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bryony Gordon helps Meet Cambridge raise over ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients to benefit from mental health unit in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Share a Cuppa this World Mental Health Day at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dallas - Fort Worth Hospital Council Foundatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thinking about mental health month</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nine in 10 united kingdom Workers Touched by M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Longford locals to light up night for mental h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Psychological Distress Declines in U . S . Adults</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Youth mental health - how schools can improve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Monzo and Starling are making banks take menta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Antidepressants were the second most prescribe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>REVEALED : Rise in number of antidepressants p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mandatory Mental Health Classes Coming To New ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>More evidence exercise may be good for your mood</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mental health talk in Coquitlam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alcoholism cited as major contributor to menta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Study finds Many Iowans with mental illness go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TK Maxx removes offensive OCD Christmas decor ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Risk Factors Identified for Suicidal Ideation ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Social Stigma Worsens Mental Health With Autism</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Siena Yates : Is mental illness what we fear m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>One in EIGHT children have mental health problems</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How stress associated with social stigma affec...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Why Kids Suffer From Depression and Mental Hea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mental health challenges facing the modern Afr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Social stigma contributes to poor mental healt...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mental health and stigma - Daily Times</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Tone\n",
       "0   # SpeakYourMind : YEP hosts free mental health...     1\n",
       "1   Ed Sheeran and Ella Eyre lead the way as stars...     1\n",
       "2   Day of play to say You Matter : youths host fi...     1\n",
       "3   Bryony Gordon helps Meet Cambridge raise over ...     1\n",
       "4   Patients to benefit from mental health unit in...     1\n",
       "5   Share a Cuppa this World Mental Health Day at ...     1\n",
       "6   Dallas - Fort Worth Hospital Council Foundatio...     1\n",
       "7                  Thinking about mental health month     1\n",
       "8   Nine in 10 united kingdom Workers Touched by M...     1\n",
       "9   Longford locals to light up night for mental h...     1\n",
       "10  Psychological Distress Declines in U . S . Adults     0\n",
       "11  Youth mental health - how schools can improve ...     0\n",
       "12  Monzo and Starling are making banks take menta...     0\n",
       "13  Antidepressants were the second most prescribe...     0\n",
       "14  REVEALED : Rise in number of antidepressants p...     0\n",
       "15  Mandatory Mental Health Classes Coming To New ...     0\n",
       "16   More evidence exercise may be good for your mood     0\n",
       "17                    Mental health talk in Coquitlam     0\n",
       "18  Alcoholism cited as major contributor to menta...     0\n",
       "19  Study finds Many Iowans with mental illness go...     0\n",
       "20  TK Maxx removes offensive OCD Christmas decor ...    -1\n",
       "21  Risk Factors Identified for Suicidal Ideation ...    -1\n",
       "22    Social Stigma Worsens Mental Health With Autism    -1\n",
       "23  Siena Yates : Is mental illness what we fear m...    -1\n",
       "24  One in EIGHT children have mental health problems    -1\n",
       "25  How stress associated with social stigma affec...    -1\n",
       "26  Why Kids Suffer From Depression and Mental Hea...    -1\n",
       "27  Mental health challenges facing the modern Afr...    -1\n",
       "28  Social stigma contributes to poor mental healt...    -1\n",
       "29             Mental health and stigma - Daily Times    -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = []\n",
    "for index, row in df_train.iterrows() :\n",
    "    corpus_train.append({'text': row['Title'], 'sentiment': str(row['Tone'])})\n",
    "corpus_test = []\n",
    "for index, row in df_test.iterrows() :\n",
    "    corpus_test.append({'text': row['Title'], 'sentiment': str(row['Tone'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data as test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = pd.DataFrame.from_dict(corpus_train)\n",
    "X_train = train_corpus.text\n",
    "y_train = train_corpus.sentiment\n",
    "\n",
    "test_corpus = pd.DataFrame.from_dict(corpus_test)\n",
    "X_test = test_corpus.text\n",
    "y_test = test_corpus.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing, Predicting using TF-IDF, HASHING OR COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = ['Teenager being offensive towards patient with autism', \n",
    "           'New mental institution in U.S', \n",
    "           'A lot of people get benefits from the new mental health institution',\n",
    "           'Man suffered from depression', \n",
    "           'Free mental health aid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "X_train_dtm = tfidf_vect.fit_transform(X_train)\n",
    "X_test_dtm = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speakyourmind': 133, 'yep': 166, 'hosts': 71, 'free': 59, 'mental': 95, 'health': 65, 'aid': 8, 'course': 33, 'leeds': 84, 'ed': 45, 'sheeran': 129, 'ella': 46, 'eyre': 50, 'lead': 83, 'way': 157, 'stars': 136, 'throw': 147, 'weight': 159, 'music': 100, 'gog': 60, 'day': 37, 'play': 109, 'say': 124, 'matter': 92, 'youths': 169, 'host': 70, 'time': 149, 'event': 47, 'bryony': 17, 'gordon': 62, 'helps': 67, 'meet': 94, 'cambridge': 19, 'raise': 116, '2k': 3, 'charity': 22, 'business': 18, 'weekly': 158, 'technology': 145, 'news': 102, 'patients': 107, 'benefit': 16, 'unit': 153, 'investment': 76, 'share': 128, 'cuppa': 34, 'world': 161, 'thyme': 148, 'lake': 82, 'dallas': 36, 'fort': 57, 'worth': 163, 'hospital': 69, 'council': 32, 'foundation': 58, 'receive': 117, 'hhsc': 68, 'grant': 63, 'state': 137, 'reform': 118, 'thinking': 146, 'month': 97, '10': 0, 'united': 154, 'kingdom': 81, 'workers': 160, 'touched': 152, 'challenges': 21, 'accenture': 4, 'research': 120, 'finds': 54, 'longford': 87, 'locals': 86, 'light': 85, 'night': 103, 'psychological': 114, 'distress': 42, 'declines': 38, 'adults': 5, 'youth': 168, 'schools': 125, 'improve': 75, 'provision': 113, 'monzo': 98, 'starling': 135, 'making': 89, 'banks': 15, 'seriously': 127, 'antidepressants': 10, 'second': 126, 'prescribed': 111, 'drug': 44, 'halton': 64, 'year': 165, 'revealed': 121, 'rise': 122, 'number': 104, 'doctors': 43, 'st': 134, 'helens': 66, 'mandatory': 91, 'classes': 26, 'coming': 27, 'new': 101, 'york': 167, 'evidence': 48, 'exercise': 49, 'good': 61, 'mood': 99, 'talk': 144, 'coquitlam': 31, 'alcoholism': 9, 'cited': 25, 'major': 88, 'contributor': 30, 'cases': 20, 'study': 140, 'iowans': 77, 'illness': 74, 'untreated': 155, 'kicd': 79, 'fm': 55, 'radio': 115, '102': 1, '1240': 2, 'tk': 151, 'maxx': 93, 'removes': 119, 'offensive': 106, 'ocd': 105, 'christmas': 24, 'decor': 39, 'following': 56, 'backlash': 14, 'risk': 123, 'factors': 52, 'identified': 73, 'suicidal': 143, 'ideation': 72, 'substance': 141, 'use': 156, 'disorders': 41, 'social': 131, 'stigma': 138, 'worsens': 162, 'autism': 12, 'siena': 130, 'yates': 164, 'fear': 53, 'society': 132, 'children': 23, 'problems': 112, 'stress': 139, 'associated': 11, 'affects': 6, 'autistic': 13, 'people': 108, 'kids': 80, 'suffer': 142, 'depression': 40, 'issues': 78, 'facing': 51, 'modern': 96, 'african': 7, 'male': 90, 'contributes': 29, 'poor': 110, 'community': 28, 'daily': 35, 'times': 150}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>102</th>\n",
       "      <th>1240</th>\n",
       "      <th>2k</th>\n",
       "      <th>accenture</th>\n",
       "      <th>adults</th>\n",
       "      <th>affects</th>\n",
       "      <th>african</th>\n",
       "      <th>aid</th>\n",
       "      <th>alcoholism</th>\n",
       "      <th>...</th>\n",
       "      <th>workers</th>\n",
       "      <th>world</th>\n",
       "      <th>worsens</th>\n",
       "      <th>worth</th>\n",
       "      <th>yates</th>\n",
       "      <th>year</th>\n",
       "      <th>yep</th>\n",
       "      <th>york</th>\n",
       "      <th>youth</th>\n",
       "      <th>youths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  102  1240        2k  accenture  adults  affects  african       aid  \\\n",
       "0  0.0  0.0   0.0  0.000000        0.0     0.0      0.0      0.0  0.371174   \n",
       "1  0.0  0.0   0.0  0.000000        0.0     0.0      0.0      0.0  0.000000   \n",
       "2  0.0  0.0   0.0  0.000000        0.0     0.0      0.0      0.0  0.000000   \n",
       "3  0.0  0.0   0.0  0.239468        0.0     0.0      0.0      0.0  0.000000   \n",
       "4  0.0  0.0   0.0  0.000000        0.0     0.0      0.0      0.0  0.000000   \n",
       "\n",
       "   alcoholism    ...     workers  world  worsens  worth  yates  year  \\\n",
       "0         0.0    ...         0.0    0.0      0.0    0.0    0.0   0.0   \n",
       "1         0.0    ...         0.0    0.0      0.0    0.0    0.0   0.0   \n",
       "2         0.0    ...         0.0    0.0      0.0    0.0    0.0   0.0   \n",
       "3         0.0    ...         0.0    0.0      0.0    0.0    0.0   0.0   \n",
       "4         0.0    ...         0.0    0.0      0.0    0.0    0.0   0.0   \n",
       "\n",
       "        yep  york  youth    youths  \n",
       "0  0.371174   0.0    0.0  0.000000  \n",
       "1  0.000000   0.0    0.0  0.000000  \n",
       "2  0.000000   0.0    0.0  0.358173  \n",
       "3  0.000000   0.0    0.0  0.000000  \n",
       "4  0.000000   0.0    0.0  0.000000  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.toarray(), columns = tfidf_vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n",
      "Prediksi:  ['1' '1' '1' '0' '-1' '0' '-1' '-1' '-1']\n",
      "Benar:  ['1' '1' '1' '0' '0' '0' '-1' '-1' '-1']\n",
      "Akurasi:  0.8888888888888888 \n",
      "Presisi:  0.9166666666666666 \n",
      "Recall:  0.8888888888888888 \n",
      "Confussion Matrix:\n",
      " [[3 0 0]\n",
      " [1 2 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "%time nb.fit(X_train_dtm, y_train)\n",
    "#Prediksi\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(\"Prediksi: \", y_pred_class)\n",
    "print(\"Benar: \", y_test.values)\n",
    "#Nilai akurasi, presisi\n",
    "akurasi = metrics.accuracy_score(y_test, y_pred_class)\n",
    "presisi = metrics.precision_score(y_test, y_pred_class, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred_class, average='weighted')\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"Akurasi: \", akurasi, \"\\nPresisi: \", presisi, \"\\nRecall: \", recall, \"\\nConfussion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1', '0', '-1', '-1', '1'], dtype='<U2')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = ['Teenager being offensive towards patient with autism', \n",
    "           'New mental institution in U.S', \n",
    "           'A lot of people get benefits from the new mental health institution',\n",
    "           'Man suffered from depression', \n",
    "           'Free mental health aid']\n",
    "\n",
    "new_article_vect = tfidf_vect.transform(testing)\n",
    "nb.predict(new_article_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HASHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vect = HashingVectorizer (alternate_sign=False, stop_words='english')\n",
    "X_train_dtm_hash = hash_vect.fit_transform(X_train)\n",
    "X_test_dtm_hash = hash_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1048576)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_dtm_hash.shape)\n",
    "print(X_train_dtm_hash.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 982 ms\n",
      "Prediksi:  ['1' '1' '1' '1' '-1' '0' '-1' '-1' '0']\n",
      "Benar:  ['1' '1' '1' '0' '0' '0' '-1' '-1' '-1']\n",
      "Akurasi:  0.6666666666666666 \n",
      "Presisi:  0.6388888888888888 \n",
      "Recall:  0.6666666666666666 \n",
      "Confussion Matrix:\n",
      " [[2 1 0]\n",
      " [1 1 1]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "%time nb.fit(X_train_dtm_hash, y_train)\n",
    "#Prediksi\n",
    "y_pred_class = nb.predict(X_test_dtm_hash)\n",
    "print(\"Prediksi: \", y_pred_class)\n",
    "print(\"Benar: \", y_test.values)\n",
    "#Nilai akurasi, presisi\n",
    "akurasi = metrics.accuracy_score(y_test, y_pred_class)\n",
    "presisi = metrics.precision_score(y_test, y_pred_class, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred_class, average='weighted')\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"Akurasi: \", akurasi, \"\\nPresisi: \", presisi, \"\\nRecall: \", recall, \"\\nConfussion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1', '0', '-1', '-1', '1'], dtype='<U2')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDIKSI LIST TITLE (VAR TESTING)\n",
    "new_article_vect = hash_vect.transform(testing)\n",
    "nb.predict(new_article_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer( stop_words='english')\n",
    "X_train_dtm_count = count_vect.fit_transform(X_train)\n",
    "X_test_dtm_count = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speakyourmind': 133, 'yep': 166, 'hosts': 71, 'free': 59, 'mental': 95, 'health': 65, 'aid': 8, 'course': 33, 'leeds': 84, 'ed': 45, 'sheeran': 129, 'ella': 46, 'eyre': 50, 'lead': 83, 'way': 157, 'stars': 136, 'throw': 147, 'weight': 159, 'music': 100, 'gog': 60, 'day': 37, 'play': 109, 'say': 124, 'matter': 92, 'youths': 169, 'host': 70, 'time': 149, 'event': 47, 'bryony': 17, 'gordon': 62, 'helps': 67, 'meet': 94, 'cambridge': 19, 'raise': 116, '2k': 3, 'charity': 22, 'business': 18, 'weekly': 158, 'technology': 145, 'news': 102, 'patients': 107, 'benefit': 16, 'unit': 153, 'investment': 76, 'share': 128, 'cuppa': 34, 'world': 161, 'thyme': 148, 'lake': 82, 'dallas': 36, 'fort': 57, 'worth': 163, 'hospital': 69, 'council': 32, 'foundation': 58, 'receive': 117, 'hhsc': 68, 'grant': 63, 'state': 137, 'reform': 118, 'thinking': 146, 'month': 97, '10': 0, 'united': 154, 'kingdom': 81, 'workers': 160, 'touched': 152, 'challenges': 21, 'accenture': 4, 'research': 120, 'finds': 54, 'longford': 87, 'locals': 86, 'light': 85, 'night': 103, 'psychological': 114, 'distress': 42, 'declines': 38, 'adults': 5, 'youth': 168, 'schools': 125, 'improve': 75, 'provision': 113, 'monzo': 98, 'starling': 135, 'making': 89, 'banks': 15, 'seriously': 127, 'antidepressants': 10, 'second': 126, 'prescribed': 111, 'drug': 44, 'halton': 64, 'year': 165, 'revealed': 121, 'rise': 122, 'number': 104, 'doctors': 43, 'st': 134, 'helens': 66, 'mandatory': 91, 'classes': 26, 'coming': 27, 'new': 101, 'york': 167, 'evidence': 48, 'exercise': 49, 'good': 61, 'mood': 99, 'talk': 144, 'coquitlam': 31, 'alcoholism': 9, 'cited': 25, 'major': 88, 'contributor': 30, 'cases': 20, 'study': 140, 'iowans': 77, 'illness': 74, 'untreated': 155, 'kicd': 79, 'fm': 55, 'radio': 115, '102': 1, '1240': 2, 'tk': 151, 'maxx': 93, 'removes': 119, 'offensive': 106, 'ocd': 105, 'christmas': 24, 'decor': 39, 'following': 56, 'backlash': 14, 'risk': 123, 'factors': 52, 'identified': 73, 'suicidal': 143, 'ideation': 72, 'substance': 141, 'use': 156, 'disorders': 41, 'social': 131, 'stigma': 138, 'worsens': 162, 'autism': 12, 'siena': 130, 'yates': 164, 'fear': 53, 'society': 132, 'children': 23, 'problems': 112, 'stress': 139, 'associated': 11, 'affects': 6, 'autistic': 13, 'people': 108, 'kids': 80, 'suffer': 142, 'depression': 40, 'issues': 78, 'facing': 51, 'modern': 96, 'african': 7, 'male': 90, 'contributes': 29, 'poor': 110, 'community': 28, 'daily': 35, 'times': 150}\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>102</th>\n",
       "      <th>1240</th>\n",
       "      <th>2k</th>\n",
       "      <th>accenture</th>\n",
       "      <th>adults</th>\n",
       "      <th>affects</th>\n",
       "      <th>african</th>\n",
       "      <th>aid</th>\n",
       "      <th>alcoholism</th>\n",
       "      <th>...</th>\n",
       "      <th>workers</th>\n",
       "      <th>world</th>\n",
       "      <th>worsens</th>\n",
       "      <th>worth</th>\n",
       "      <th>yates</th>\n",
       "      <th>year</th>\n",
       "      <th>yep</th>\n",
       "      <th>york</th>\n",
       "      <th>youth</th>\n",
       "      <th>youths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  102  1240  2k  accenture  adults  affects  african  aid  alcoholism  \\\n",
       "0   0    0     0   0          0       0        0        0    1           0   \n",
       "1   0    0     0   0          0       0        0        0    0           0   \n",
       "2   0    0     0   0          0       0        0        0    0           0   \n",
       "3   0    0     0   1          0       0        0        0    0           0   \n",
       "4   0    0     0   0          0       0        0        0    0           0   \n",
       "\n",
       "    ...    workers  world  worsens  worth  yates  year  yep  york  youth  \\\n",
       "0   ...          0      0        0      0      0     0    1     0      0   \n",
       "1   ...          0      0        0      0      0     0    0     0      0   \n",
       "2   ...          0      0        0      0      0     0    0     0      0   \n",
       "3   ...          0      0        0      0      0     0    0     0      0   \n",
       "4   ...          0      0        0      0      0     0    0     0      0   \n",
       "\n",
       "   youths  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm_count.toarray(), columns = count_vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n",
      "Prediksi:  ['1' '1' '1' '1' '-1' '0' '-1' '-1' '-1']\n",
      "Benar:  ['1' '1' '1' '0' '0' '0' '-1' '-1' '-1']\n",
      "Akurasi:  0.7777777777777778 \n",
      "Presisi:  0.8333333333333334 \n",
      "Recall:  0.7777777777777778 \n",
      "Confussion Matrix:\n",
      " [[3 0 0]\n",
      " [1 1 1]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "%time nb.fit(X_train_dtm_count, y_train)\n",
    "#Prediksi\n",
    "y_pred_class = nb.predict(X_test_dtm_count)\n",
    "print(\"Prediksi: \", y_pred_class)\n",
    "print(\"Benar: \", y_test.values)\n",
    "#Nilai akurasi, presisi\n",
    "akurasi = metrics.accuracy_score(y_test, y_pred_class)\n",
    "presisi = metrics.precision_score(y_test, y_pred_class, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred_class, average='weighted')\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"Akurasi: \", akurasi, \"\\nPresisi: \", presisi, \"\\nRecall: \", recall, \"\\nConfussion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1', '0', '-1', '-1', '1'], dtype='<U2')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDIKSI LIST TITLE (VAR TESTING)\n",
    "new_article_vect = count_vect.transform(testing)\n",
    "nb.predict(new_article_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
